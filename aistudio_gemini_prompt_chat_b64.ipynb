{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKwyTRdwB8aW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlE8UqxrDIez"
      },
      "source": [
        "### Install & import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cZiU4TKzznh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61537f6c-6282-4cdd-9803-41eb6a7acb22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/137.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m92.2/137.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kWIuwKG2_oWE"
      },
      "outputs": [],
      "source": [
        "# import necessary modules.\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import base64\n",
        "import pathlib\n",
        "import pprint\n",
        "import requests\n",
        "import mimetypes\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fet3lFjdKHEM"
      },
      "source": [
        "## Set the API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoRWILAtCzBE"
      },
      "source": [
        "Add your API_KEY to the secrets manager in the left pannel \"üîë\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LaLCwNlkCyQd"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "API_KEY=userdata.get('API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_SvYoR3WCeKr"
      },
      "outputs": [],
      "source": [
        "\n",
        "genai.configure(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import base64\n",
        "\n",
        "# String to encode\n",
        "input_string = \"What is the fastest car in the world? and give the specifications of that\"\n",
        "\n",
        "# Encode the string to Base64\n",
        "encoded_bytes = base64.b64encode(input_string.encode(\"utf-8\"))\n",
        "\n",
        "# Convert bytes to a string\n",
        "encoded_string = encoded_bytes.decode(\"utf-8\")\n",
        "\n",
        "print(\"Encoded Base64 string:\", encoded_string)"
      ],
      "metadata": {
        "id": "R_o3CQHqItaS",
        "outputId": "990d4444-8b35-4c28-ca9e-e072b84f32df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Base64 string: V2hhdCBpcyB0aGUgZmFzdGVzdCBjYXIgaW4gdGhlIHdvcmxkPyBhbmQgZ2l2ZSB0aGUgc3BlY2lmaWNhdGlvbnMgb2YgdGhhdA==\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weo-o73WDpdm"
      },
      "source": [
        "### Parse the arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "uIog-0SyDuIF"
      },
      "outputs": [],
      "source": [
        "model = 'gemini-1.0-pro'\n",
        "contents_b64 = 'W3sicm9sZSI6InVzZXIiLCJwYXJ0cyI6IldoYXQgaXMgdGhlIGZhc3Rlc3QgY2FyIGluIHRoZSB3b3JsZCBhbmQgbWVudGlvbiBpdHMgc3BlY2lmaWNhdGlvbnM/In0seyJyb2xlIjoibW9kZWwiLCJwYXJ0cyI6IuKAiyJ9XQ=='\n",
        "generation_config_b64 = 'eyJ0ZW1wZXJhdHVyZSI6MC45LCJ0b3BfcCI6MSwidG9wX2siOjEsIm1heF9vdXRwdXRfdG9rZW5zIjoyMDQ4LCJzdG9wX3NlcXVlbmNlcyI6W119'\n",
        "safety_settings_b64 = 'W3siY2F0ZWdvcnkiOiJIQVJNX0NBVEVHT1JZX0hBUkFTU01FTlQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfSEFURV9TUEVFQ0giLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfU0VYVUFMTFlfRVhQTElDSVQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfREFOR0VST1VTX0NPTlRFTlQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn1d'\n",
        "user_input_b64 = encoded_string\n",
        "\n",
        "contents = json.loads(base64.b64decode(contents_b64))\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "user_input = base64.b64decode(user_input_b64).decode()\n",
        "stream = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wBS8xNhN0x62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb02d48-1f05-4e9f-9b58-f37205c79dfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'parts': 'What is the fastest car in the world and mention its specifications?'},\n",
              " {'role': 'model', 'parts': '\\u200b'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1681593ef561",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716918ad-35d9-4517-b374-1b7c4e33149f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'temperature': 0.9,\n",
              " 'top_p': 1,\n",
              " 'top_k': 1,\n",
              " 'max_output_tokens': 2048,\n",
              " 'stop_sequences': []}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "generation_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "a2c31f8f1894",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f79512-bfdb-4bba-862d-f66e76364200"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'category': 'HARM_CATEGORY_HARASSMENT',\n",
              "  'threshold': 'BLOCK_MEDIUM_AND_ABOVE'},\n",
              " {'category': 'HARM_CATEGORY_HATE_SPEECH',\n",
              "  'threshold': 'BLOCK_MEDIUM_AND_ABOVE'},\n",
              " {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n",
              "  'threshold': 'BLOCK_MEDIUM_AND_ABOVE'},\n",
              " {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT',\n",
              "  'threshold': 'BLOCK_MEDIUM_AND_ABOVE'}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "safety_settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4d17bac9fefc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5e416919-6cd7-4a77-85f8-68ec90ded5bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the fastest car in the world? and give the specifications of that'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "user_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7zAD69vE92b"
      },
      "source": [
        "### Call the API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LB2LxPmAB95V"
      },
      "outputs": [],
      "source": [
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "chat = gemini.start_chat(history=contents)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\n",
        "    user_input,\n",
        "    stream=stream)"
      ],
      "metadata": {
        "id": "M3jR96rIJEBH"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Lm3RXwYuGtZK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "2d52db2c-208e-406d-c22c-50f6f6b48ec9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**SSC Tuatara**\n\n**Specifications:**\n\n* **Engine:** 5.9-liter twin-turbocharged V8\n* **Power:** 1,750 horsepower (1,305 kilowatts)\n* **Torque:** 1,280 lb-ft (1,735 Newton-meters)\n* **Transmission:** 7-speed automated manual\n* **Top speed:** 316.11 mph (508.73 km/h)\n\n**Additional features:**\n\n* Carbon fiber monocoque chassis\n* Active rear wing\n* Adjustable suspension\n* Aerodynamic design with a drag coefficient of 0.279\n* Bespoke interior with premium materials\n* Limited production of 100 units"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NV_EmLGeJhZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarization"
      ],
      "metadata": {
        "id": "aCi6ys9oJidZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import base64\n",
        "\n",
        "# String to encode\n",
        "input_string = \"\"\"\n",
        "Summarize the below conversation:\n",
        "Anjali ‚Äì Hi, Raj. How was your weekend?\n",
        "Raj ‚Äì Hey, Anjali. My weekend was great. I watched a great movie.\n",
        "\n",
        "Anjali ‚Äì Oh really? What was the name of the movie you watched?\n",
        "\n",
        "Raj ‚Äì I watched Avengers Endgame. It is the last movie of the Avengers.\n",
        "\n",
        "Anjali ‚Äì Oh, I have watched Avengers Endgame too. I loved the movie.\n",
        "\n",
        "Raj ‚Äì Really? Who is your favourite Avenger?\n",
        "\n",
        "Anjali ‚Äì I can‚Äôt name one! Iron Man, Thor, Captain America, Captain Marvel, Scarlet Witch and Black Widow, to name a few.\n",
        "\n",
        "Raj ‚Äì Wow, you have some of the strongest Avengers there! I have the same choice except that I loved Spider Man too.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Encode the string to Base64\n",
        "encoded_bytes = base64.b64encode(input_string.encode(\"utf-8\"))\n",
        "\n",
        "# Convert bytes to a string\n",
        "encoded_string = encoded_bytes.decode(\"utf-8\")\n",
        "\n",
        "print(\"Encoded Base64 string:\", encoded_string)"
      ],
      "metadata": {
        "id": "IFaUzAEhJ5mX",
        "outputId": "c2cd1c0a-930f-48d7-b3da-8781e87b912c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Base64 string: ClN1bW1hcml6ZSB0aGUgYmVsb3cgY29udmVyc2F0aW9uOgpBbmphbGkg4oCTIEhpLCBSYWouIEhvdyB3YXMgeW91ciB3ZWVrZW5kPwpSYWog4oCTIEhleSwgQW5qYWxpLiBNeSB3ZWVrZW5kIHdhcyBncmVhdC4gSSB3YXRjaGVkIGEgZ3JlYXQgbW92aWUuCgpBbmphbGkg4oCTIE9oIHJlYWxseT8gV2hhdCB3YXMgdGhlIG5hbWUgb2YgdGhlIG1vdmllIHlvdSB3YXRjaGVkPwoKUmFqIOKAkyBJIHdhdGNoZWQgQXZlbmdlcnMgRW5kZ2FtZS4gSXQgaXMgdGhlIGxhc3QgbW92aWUgb2YgdGhlIEF2ZW5nZXJzLgoKQW5qYWxpIOKAkyBPaCwgSSBoYXZlIHdhdGNoZWQgQXZlbmdlcnMgRW5kZ2FtZSB0b28uIEkgbG92ZWQgdGhlIG1vdmllLgoKUmFqIOKAkyBSZWFsbHk/IFdobyBpcyB5b3VyIGZhdm91cml0ZSBBdmVuZ2VyPwoKQW5qYWxpIOKAkyBJIGNhbuKAmXQgbmFtZSBvbmUhIElyb24gTWFuLCBUaG9yLCBDYXB0YWluIEFtZXJpY2EsIENhcHRhaW4gTWFydmVsLCBTY2FybGV0IFdpdGNoIGFuZCBCbGFjayBXaWRvdywgdG8gbmFtZSBhIGZldy4KClJhaiDigJMgV293LCB5b3UgaGF2ZSBzb21lIG9mIHRoZSBzdHJvbmdlc3QgQXZlbmdlcnMgdGhlcmUhIEkgaGF2ZSB0aGUgc2FtZSBjaG9pY2UgZXhjZXB0IHRoYXQgSSBsb3ZlZCBTcGlkZXIgTWFuIHRvby4KCgo=\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'gemini-1.0-pro'\n",
        "contents_b64 = 'W3sicm9sZSI6InVzZXIiLCJwYXJ0cyI6IldoYXQgaXMgdGhlIGZhc3Rlc3QgY2FyIGluIHRoZSB3b3JsZCBhbmQgbWVudGlvbiBpdHMgc3BlY2lmaWNhdGlvbnM/In0seyJyb2xlIjoibW9kZWwiLCJwYXJ0cyI6IuKAiyJ9XQ=='\n",
        "generation_config_b64 = 'eyJ0ZW1wZXJhdHVyZSI6MC45LCJ0b3BfcCI6MSwidG9wX2siOjEsIm1heF9vdXRwdXRfdG9rZW5zIjoyMDQ4LCJzdG9wX3NlcXVlbmNlcyI6W119'\n",
        "safety_settings_b64 = 'W3siY2F0ZWdvcnkiOiJIQVJNX0NBVEVHT1JZX0hBUkFTU01FTlQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfSEFURV9TUEVFQ0giLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfU0VYVUFMTFlfRVhQTElDSVQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfREFOR0VST1VTX0NPTlRFTlQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn1d'\n",
        "user_input_b64 = encoded_string\n",
        "\n",
        "contents = json.loads(base64.b64decode(contents_b64))\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "user_input = base64.b64decode(user_input_b64).decode()\n",
        "stream = False"
      ],
      "metadata": {
        "id": "upVpV6lNJj9B"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "chat = gemini.start_chat(history=contents)\n"
      ],
      "metadata": {
        "id": "PJfm8ioDKKvk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\n",
        "    user_input,\n",
        "    stream=stream)"
      ],
      "metadata": {
        "id": "4CdXgc8KKKxv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "id": "Z8I_QTW_KK0L",
        "outputId": "b5824623-6621-4b5c-de5f-a3ecaafa7404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Anjali and Raj discussed their weekend, revealing they both watched \"Avengers: Endgame.\" They expressed mutual appreciation for the movie and shared their favorite Avengers, acknowledging the strengths of multiple characters such as Iron Man, Thor, Captain America, and Spider-Man."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JSJJ4-wdKK2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification"
      ],
      "metadata": {
        "id": "UWtAxRiNJkhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import base64\n",
        "\n",
        "# String to encode\n",
        "input_string = \"\"\"\n",
        "Classify the emotional state of the two friends in the conversation:\n",
        "\n",
        "Friend 1: Hey, how are you doing?\n",
        "Friend 2: Not so great, to be honest. I've been feeling really down lately.\n",
        "Friend 1: Oh no, what's been going on?\n",
        "Friend 2: It's just... everything feels so overwhelming. I'm struggling with work, and I don't even know where to start.\n",
        "Friend 1: I'm really sorry to hear that. Is there anything I can do to help?\n",
        "Friend 2: I appreciate it, but I don't even know what would help at this point. I just feel so lost.\n",
        "Friend 1: I understand. Sometimes it's hard to see a way forward when everything seems dark. Just know that I'm here for you, no matter what.\n",
        "Friend 2: Thanks, it means a lot to me. I'm just really tired of feeling like this all the time.\n",
        "Friend 1: I wish I could take away your pain, but I know it doesn't work that way. Just know that I care about you, and I'll always be here to listen.\n",
        "Friend 2: Thank you, that means more to me than you'll ever know.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Encode the string to Base64\n",
        "encoded_bytes = base64.b64encode(input_string.encode(\"utf-8\"))\n",
        "\n",
        "# Convert bytes to a string\n",
        "encoded_string = encoded_bytes.decode(\"utf-8\")\n",
        "\n",
        "print(\"Encoded Base64 string:\", encoded_string)"
      ],
      "metadata": {
        "id": "4fnA118rJl2y",
        "outputId": "be1cb9fe-46bd-47e9-ca90-94629b333e18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Base64 string: CkNsYXNzaWZ5IHRoZSBlbW90aW9uYWwgc3RhdGUgb2YgdGhlIHR3byBmcmllbmRzIGluIHRoZSBjb252ZXJzYXRpb246CgpGcmllbmQgMTogSGV5LCBob3cgYXJlIHlvdSBkb2luZz8KRnJpZW5kIDI6IE5vdCBzbyBncmVhdCwgdG8gYmUgaG9uZXN0LiBJJ3ZlIGJlZW4gZmVlbGluZyByZWFsbHkgZG93biBsYXRlbHkuCkZyaWVuZCAxOiBPaCBubywgd2hhdCdzIGJlZW4gZ29pbmcgb24/CkZyaWVuZCAyOiBJdCdzIGp1c3QuLi4gZXZlcnl0aGluZyBmZWVscyBzbyBvdmVyd2hlbG1pbmcuIEknbSBzdHJ1Z2dsaW5nIHdpdGggd29yaywgYW5kIEkgZG9uJ3QgZXZlbiBrbm93IHdoZXJlIHRvIHN0YXJ0LgpGcmllbmQgMTogSSdtIHJlYWxseSBzb3JyeSB0byBoZWFyIHRoYXQuIElzIHRoZXJlIGFueXRoaW5nIEkgY2FuIGRvIHRvIGhlbHA/CkZyaWVuZCAyOiBJIGFwcHJlY2lhdGUgaXQsIGJ1dCBJIGRvbid0IGV2ZW4ga25vdyB3aGF0IHdvdWxkIGhlbHAgYXQgdGhpcyBwb2ludC4gSSBqdXN0IGZlZWwgc28gbG9zdC4KRnJpZW5kIDE6IEkgdW5kZXJzdGFuZC4gU29tZXRpbWVzIGl0J3MgaGFyZCB0byBzZWUgYSB3YXkgZm9yd2FyZCB3aGVuIGV2ZXJ5dGhpbmcgc2VlbXMgZGFyay4gSnVzdCBrbm93IHRoYXQgSSdtIGhlcmUgZm9yIHlvdSwgbm8gbWF0dGVyIHdoYXQuCkZyaWVuZCAyOiBUaGFua3MsIGl0IG1lYW5zIGEgbG90IHRvIG1lLiBJJ20ganVzdCByZWFsbHkgdGlyZWQgb2YgZmVlbGluZyBsaWtlIHRoaXMgYWxsIHRoZSB0aW1lLgpGcmllbmQgMTogSSB3aXNoIEkgY291bGQgdGFrZSBhd2F5IHlvdXIgcGFpbiwgYnV0IEkga25vdyBpdCBkb2Vzbid0IHdvcmsgdGhhdCB3YXkuIEp1c3Qga25vdyB0aGF0IEkgY2FyZSBhYm91dCB5b3UsIGFuZCBJJ2xsIGFsd2F5cyBiZSBoZXJlIHRvIGxpc3Rlbi4KRnJpZW5kIDI6IFRoYW5rIHlvdSwgdGhhdCBtZWFucyBtb3JlIHRvIG1lIHRoYW4geW91J2xsIGV2ZXIga25vdy4KCg==\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'gemini-1.0-pro'\n",
        "contents_b64 = 'W3sicm9sZSI6InVzZXIiLCJwYXJ0cyI6IldoYXQgaXMgdGhlIGZhc3Rlc3QgY2FyIGluIHRoZSB3b3JsZCBhbmQgbWVudGlvbiBpdHMgc3BlY2lmaWNhdGlvbnM/In0seyJyb2xlIjoibW9kZWwiLCJwYXJ0cyI6IuKAiyJ9XQ=='\n",
        "generation_config_b64 = 'eyJ0ZW1wZXJhdHVyZSI6MC45LCJ0b3BfcCI6MSwidG9wX2siOjEsIm1heF9vdXRwdXRfdG9rZW5zIjoyMDQ4LCJzdG9wX3NlcXVlbmNlcyI6W119'\n",
        "safety_settings_b64 = 'W3siY2F0ZWdvcnkiOiJIQVJNX0NBVEVHT1JZX0hBUkFTU01FTlQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfSEFURV9TUEVFQ0giLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfU0VYVUFMTFlfRVhQTElDSVQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfREFOR0VST1VTX0NPTlRFTlQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn1d'\n",
        "user_input_b64 = encoded_string\n",
        "\n",
        "contents = json.loads(base64.b64decode(contents_b64))\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "user_input = base64.b64decode(user_input_b64).decode()\n",
        "stream = False"
      ],
      "metadata": {
        "id": "luCWzxnZK4Nl"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "chat = gemini.start_chat(history=contents)\n"
      ],
      "metadata": {
        "id": "yW0tKnXtKaVN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\n",
        "    user_input,\n",
        "    stream=stream)"
      ],
      "metadata": {
        "id": "CWvxtbh5KaXq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "id": "J8bAE61uKab1",
        "outputId": "a0926959-ba2d-475c-c949-3ff49668babb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Friend 1: Concerned and empathetic\nFriend 2: Sad, overwhelmed, and lost"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generation"
      ],
      "metadata": {
        "id": "lLtWUYhgJmW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import base64\n",
        "\n",
        "# String to encode\n",
        "input_string = \"\"\"\n",
        "What is the difference between a Llama, Gemini and Falcon in terms of AI?\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Encode the string to Base64\n",
        "encoded_bytes = base64.b64encode(input_string.encode(\"utf-8\"))\n",
        "\n",
        "# Convert bytes to a string\n",
        "encoded_string = encoded_bytes.decode(\"utf-8\")\n",
        "\n",
        "print(\"Encoded Base64 string:\", encoded_string)"
      ],
      "metadata": {
        "id": "TDNQ5mH3JoIn",
        "outputId": "5483135f-e952-46c4-83ee-e0be77776928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Base64 string: CldoYXQgaXMgdGhlIGRpZmZlcmVuY2UgYmV0d2VlbiBhIExsYW1hLCBHZW1pbmkgYW5kIEZhbGNvbiBpbiB0ZXJtcyBvZiBBST8KCg==\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'gemini-1.0-pro'\n",
        "contents_b64 = 'W3sicm9sZSI6InVzZXIiLCJwYXJ0cyI6IldoYXQgaXMgdGhlIGZhc3Rlc3QgY2FyIGluIHRoZSB3b3JsZCBhbmQgbWVudGlvbiBpdHMgc3BlY2lmaWNhdGlvbnM/In0seyJyb2xlIjoibW9kZWwiLCJwYXJ0cyI6IuKAiyJ9XQ=='\n",
        "generation_config_b64 = 'eyJ0ZW1wZXJhdHVyZSI6MC45LCJ0b3BfcCI6MSwidG9wX2siOjEsIm1heF9vdXRwdXRfdG9rZW5zIjoyMDQ4LCJzdG9wX3NlcXVlbmNlcyI6W119'\n",
        "safety_settings_b64 = 'W3siY2F0ZWdvcnkiOiJIQVJNX0NBVEVHT1JZX0hBUkFTU01FTlQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfSEFURV9TUEVFQ0giLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfU0VYVUFMTFlfRVhQTElDSVQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfREFOR0VST1VTX0NPTlRFTlQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn1d'\n",
        "user_input_b64 = encoded_string\n",
        "\n",
        "contents = json.loads(base64.b64decode(contents_b64))\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "user_input = base64.b64decode(user_input_b64).decode()\n",
        "stream = False"
      ],
      "metadata": {
        "id": "jOpZdt4LLQxJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "chat = gemini.start_chat(history=contents)\n"
      ],
      "metadata": {
        "id": "cAbMep4WLRDZ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\n",
        "    user_input,\n",
        "    stream=stream)"
      ],
      "metadata": {
        "id": "SDpeLAJXLSul"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "id": "t_szU37_LUvI",
        "outputId": "b2ce5f2e-5cf8-4716-f7b6-d5ce56167bfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Llama, Gemini, and Falcon** are all large language models developed by different companies. Here's a comparison of their key characteristics:\n\n| **Feature** | **Llama** | **Gemini** | **Falcon** |\n|---|---|---|---|\n| **Developer** | Meta | Google | Google |\n| **Size** | 65 billion parameters | 175 billion parameters | 540 billion parameters |\n| **Training Data** | Text and code | Text, code, and images | Text, code, images, and videos |\n| **Tasks** | Natural language processing, question answering, code generation | Natural language processing, question answering, dialogue generation | Natural language processing, question answering, image and video generation |\n| **Strengths** | Efficient and accurate text generation | Comprehensive knowledge and reasoning abilities | Multimodal capabilities (text, code, images, videos) |\n| **Weaknesses** | May struggle with complex or factual questions | Limited real-world knowledge | Requires significant computational resources |\n| **Applications** | Chatbots, language translation, content generation | Search engines, question answering systems | Creative content generation, image and video editing |\n\n**Summary:**\n\n* **Llama:** A relatively smaller model that excels in text generation tasks, known for its efficiency and accuracy.\n* **Gemini:** A larger model with strong knowledge and reasoning capabilities, suitable for complex question answering and dialogue generation.\n* **Falcon:** The largest and most comprehensive model, capable of handling multimodal tasks involving text, code, images, and videos. However, it requires substantial computational resources.\n\nIt's important to note that these models are still under development and their capabilities continue to evolve."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import base64\n",
        "\n",
        "# String to encode\n",
        "input_string = \"\"\"\n",
        "Write a short email to your friend about his health concern\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Encode the string to Base64\n",
        "encoded_bytes = base64.b64encode(input_string.encode(\"utf-8\"))\n",
        "\n",
        "# Convert bytes to a string\n",
        "encoded_string = encoded_bytes.decode(\"utf-8\")\n",
        "\n",
        "print(\"Encoded Base64 string:\", encoded_string)"
      ],
      "metadata": {
        "id": "dTWrgHflLWUD",
        "outputId": "651a1899-004a-4ad3-9040-19d57447f709",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Base64 string: CldyaXRlIGEgc2hvcnQgZW1haWwgdG8geW91ciBmcmllbmQgYWJvdXQgaGlzIGhlYWx0aCBjb25jZXJuCgo=\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'gemini-1.0-pro'\n",
        "contents_b64 = 'W3sicm9sZSI6InVzZXIiLCJwYXJ0cyI6IldoYXQgaXMgdGhlIGZhc3Rlc3QgY2FyIGluIHRoZSB3b3JsZCBhbmQgbWVudGlvbiBpdHMgc3BlY2lmaWNhdGlvbnM/In0seyJyb2xlIjoibW9kZWwiLCJwYXJ0cyI6IuKAiyJ9XQ=='\n",
        "generation_config_b64 = 'eyJ0ZW1wZXJhdHVyZSI6MC45LCJ0b3BfcCI6MSwidG9wX2siOjEsIm1heF9vdXRwdXRfdG9rZW5zIjoyMDQ4LCJzdG9wX3NlcXVlbmNlcyI6W119'\n",
        "safety_settings_b64 = 'W3siY2F0ZWdvcnkiOiJIQVJNX0NBVEVHT1JZX0hBUkFTU01FTlQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfSEFURV9TUEVFQ0giLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfU0VYVUFMTFlfRVhQTElDSVQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn0seyJjYXRlZ29yeSI6IkhBUk1fQ0FURUdPUllfREFOR0VST1VTX0NPTlRFTlQiLCJ0aHJlc2hvbGQiOiJCTE9DS19NRURJVU1fQU5EX0FCT1ZFIn1d'\n",
        "user_input_b64 = encoded_string\n",
        "\n",
        "contents = json.loads(base64.b64decode(contents_b64))\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "user_input = base64.b64decode(user_input_b64).decode()\n",
        "stream = False"
      ],
      "metadata": {
        "id": "0EvZjJjkLq61"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "chat = gemini.start_chat(history=contents)\n"
      ],
      "metadata": {
        "id": "bAuFF0tHLspI"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\n",
        "    user_input,\n",
        "    stream=stream)"
      ],
      "metadata": {
        "id": "iKl8xkFjLxbl"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "id": "QhL-dWxFLuST",
        "outputId": "84516d25-f8d5-44b1-c956-1cc5ca8033e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Sure, here is a short email to your friend about his health concern:\n\nHi [friend's name],\n\nI'm writing to you today because I'm concerned about your health. I've noticed that you've been losing weight, and you don't seem to have as much energy as you used to. I'm worried that you might be sick, and I want to make sure that you're okay.\n\nI know that you're a private person, but I hope you'll be open with me about what's going on. If you're not feeling well, please don't hesitate to reach out to me. I'm here for you, and I want to help you get better.\n\nIn the meantime, please take care of yourself. Eat healthy foods, get plenty of rest, and exercise regularly. I'm sure that you'll start to feel better soon.\n\nI'm thinking of you, and I'm sending you all my love.\n\nLove,\n[Your name]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XfcB6C-oLzvP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "aistudio_gemini_prompt_chat_b64.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}